=============================================
   Ejecucion pr3 sobre wine.data dataset!
=============================================

EJERCICIO 2 (SVM  kernel lineal dataset completo train/test):
acc.: 100.00%
kappa: 100.00%
cf = 
[[59  0  0]
 [ 0 71  0]
 [ 0  0 48]]

─────────────────────────────────────────────────
EJERCICIO 3 (SVM gaussian kernel sobre dataset completo train/test):
acc.: 100.00%
kappa: 100.00%
cf = 
[[59  0  0]
 [ 0 71  0]
 [ 0  0 48]]

─────────────────────────────────────────────────
EJERCICIO 4_1 (SVM cross_validation, linear kernel, K=4):
Sintonizacion:
         L   Kappa(%)
      0.03       94.7
      0.12       93.9
      0.50       95.6
      2.00       95.6
      8.00       95.6
     32.00       95.6
    128.00       95.6
    512.00       95.6
   2048.00       95.6
   8192.00       95.6
  32768.00       95.6
V_mejor=0 kappa=95.63%

Test:
acc.: 96.94%
kappa: 95.30%
cf = 
[[16.75  0.25  0.  ]
 [ 0.   19.5   0.5 ]
 [ 0.    0.75 11.25]]
─────────────────────────────────────────────────
EJERCICIO 4_2 (SVM cross_validation, linear kernel, K=10):
Sintonizacion:
         L   Kappa(%)
      0.03       98.1
      0.12       96.2
      0.50       96.1
      2.00       95.2
      8.00       95.2
     32.00       95.2
    128.00       95.2
    512.00       95.2
   2048.00       95.2
   8192.00       95.2
  32768.00       95.2
V_mejor=0 kappa=98.14%

Test:
acc.: 99.41%
kappa: 99.09%
cf = 
[[14.   0.   0. ]
 [ 0.   7.8  0.2]
 [ 0.   0.  12. ]]
─────────────────────────────────────────────────
EJERCICIO 4_3 (SVM cross_validation, gaussian kernel, K=4):
Sintonizacion:
    Lambda           Gamma  Kappa (%)      Mejor
0.03       0.0078125        0.0        0.0
0.03         0.03125        0.0        0.0
0.03           0.125        0.0        0.0
0.03             0.5        0.0        0.0
0.03               2        0.0        0.0
0.03               8        0.0        0.0
0.03              32        0.0        0.0
0.03             128        0.0        0.0
0.12       0.0078125        0.0        0.0
0.12         0.03125       93.8       93.8
0.12           0.125       82.9       93.8
0.12             0.5        0.0       93.8
0.12               2        0.0       93.8
0.12               8        0.0       93.8
0.12              32        0.0       93.8
0.12             128        0.0       93.8
0.50       0.0078125       96.5       96.5
0.50         0.03125       97.4       97.4
0.50           0.125       96.5       97.4
0.50             0.5       34.3       97.4
0.50               2        0.0       97.4
0.50               8        0.0       97.4
0.50              32        0.0       97.4
0.50             128        0.0       97.4
2.00       0.0078125       97.4       97.4
2.00         0.03125       95.6       97.4
2.00           0.125       95.6       97.4
2.00             0.5       78.4       97.4
2.00               2        0.0       97.4
2.00               8        0.0       97.4
2.00              32        0.0       97.4
2.00             128        0.0       97.4
8.00       0.0078125       95.6       97.4
8.00         0.03125       94.7       97.4
8.00           0.125       95.6       97.4
8.00             0.5       78.4       97.4
8.00               2        0.0       97.4
8.00               8        0.0       97.4
8.00              32        0.0       97.4
8.00             128        0.0       97.4
32.00       0.0078125       93.9       97.4
32.00         0.03125       93.9       97.4
32.00           0.125       95.6       97.4
32.00             0.5       78.4       97.4
32.00               2        0.0       97.4
32.00               8        0.0       97.4
32.00              32        0.0       97.4
32.00             128        0.0       97.4
128.00       0.0078125       93.9       97.4
128.00         0.03125       93.9       97.4
128.00           0.125       95.6       97.4
128.00             0.5       78.4       97.4
128.00               2        0.0       97.4
128.00               8        0.0       97.4
128.00              32        0.0       97.4
128.00             128        0.0       97.4
512.00       0.0078125       93.9       97.4
512.00         0.03125       93.9       97.4
512.00           0.125       95.6       97.4
512.00             0.5       78.4       97.4
512.00               2        0.0       97.4
512.00               8        0.0       97.4
512.00              32        0.0       97.4
512.00             128        0.0       97.4
2048.00       0.0078125       93.9       97.4
2048.00         0.03125       93.9       97.4
2048.00           0.125       95.6       97.4
2048.00             0.5       78.4       97.4
2048.00               2        0.0       97.4
2048.00               8        0.0       97.4
2048.00              32        0.0       97.4
2048.00             128        0.0       97.4
8192.00       0.0078125       93.9       97.4
8192.00         0.03125       93.9       97.4
8192.00           0.125       95.6       97.4
8192.00             0.5       78.4       97.4
8192.00               2        0.0       97.4
8192.00               8        0.0       97.4
8192.00              32        0.0       97.4
8192.00             128        0.0       97.4
32768.00       0.0078125       93.9       97.4
32768.00         0.03125       93.9       97.4
32768.00           0.125       95.6       97.4
32768.00             0.5       78.4       97.4
32768.00               2        0.0       97.4
32768.00               8        0.0       97.4
32768.00              32        0.0       97.4
32768.00             128        0.0       97.4
L_mejor=2, G_mejor=0.0078125, kappa=97.37%

Test:
acc.: 98.47%
kappa: 97.67%
cf = 
[[17.    0.    0.  ]
 [ 0.   19.25  0.75]
 [ 0.    0.   12.  ]]
─────────────────────────────────────────────────
EJERCICIO 4_4 (SVM cross_validation, gaussian kernel, K=10):
Sintonizacion:
    Lambda           Gamma  Kappa (%)      Mejor
0.03       0.0078125        0.0        0.0
0.03         0.03125        0.0        0.0
0.03           0.125        0.0        0.0
0.03             0.5        0.0        0.0
0.03               2        0.0        0.0
0.03               8        0.0        0.0
0.03              32        0.0        0.0
0.03             128        0.0        0.0
0.12       0.0078125       18.3       18.3
0.12         0.03125       95.1       95.1
0.12           0.125       91.0       95.1
0.12             0.5        0.0       95.1
0.12               2        0.0       95.1
0.12               8        0.0       95.1
0.12              32        0.0       95.1
0.12             128        0.0       95.1
0.50       0.0078125       96.1       96.1
0.50         0.03125       98.1       98.1
0.50           0.125       95.1       98.1
0.50             0.5       46.0       98.1
0.50               2        0.0       98.1
0.50               8        0.0       98.1
0.50              32        0.0       98.1
0.50             128        0.0       98.1
2.00       0.0078125       98.1       98.1
2.00         0.03125       97.1       98.1
2.00           0.125       96.1       98.1
2.00             0.5       82.8       98.1
2.00               2        0.0       98.1
2.00               8        0.0       98.1
2.00              32        0.0       98.1
2.00             128        0.0       98.1
8.00       0.0078125       96.2       98.1
8.00         0.03125       96.2       98.1
8.00           0.125       96.1       98.1
8.00             0.5       82.8       98.1
8.00               2        0.0       98.1
8.00               8        0.0       98.1
8.00              32        0.0       98.1
8.00             128        0.0       98.1
32.00       0.0078125       94.3       98.1
32.00         0.03125       96.2       98.1
32.00           0.125       96.1       98.1
32.00             0.5       82.8       98.1
32.00               2        0.0       98.1
32.00               8        0.0       98.1
32.00              32        0.0       98.1
32.00             128        0.0       98.1
128.00       0.0078125       94.3       98.1
128.00         0.03125       96.2       98.1
128.00           0.125       96.1       98.1
128.00             0.5       82.8       98.1
128.00               2        0.0       98.1
128.00               8        0.0       98.1
128.00              32        0.0       98.1
128.00             128        0.0       98.1
512.00       0.0078125       94.3       98.1
512.00         0.03125       96.2       98.1
512.00           0.125       96.1       98.1
512.00             0.5       82.8       98.1
512.00               2        0.0       98.1
512.00               8        0.0       98.1
512.00              32        0.0       98.1
512.00             128        0.0       98.1
2048.00       0.0078125       94.3       98.1
2048.00         0.03125       96.2       98.1
2048.00           0.125       96.1       98.1
2048.00             0.5       82.8       98.1
2048.00               2        0.0       98.1
2048.00               8        0.0       98.1
2048.00              32        0.0       98.1
2048.00             128        0.0       98.1
8192.00       0.0078125       94.3       98.1
8192.00         0.03125       96.2       98.1
8192.00           0.125       96.1       98.1
8192.00             0.5       82.8       98.1
8192.00               2        0.0       98.1
8192.00               8        0.0       98.1
8192.00              32        0.0       98.1
8192.00             128        0.0       98.1
32768.00       0.0078125       94.3       98.1
32768.00         0.03125       96.2       98.1
32768.00           0.125       96.1       98.1
32768.00             0.5       82.8       98.1
32768.00               2        0.0       98.1
32768.00               8        0.0       98.1
32768.00              32        0.0       98.1
32768.00             128        0.0       98.1
L_mejor=0.5, G_mejor=0.03125, kappa=98.08%

Test:
acc.: 99.12%
kappa: 98.65%
cf = 
[[13.8  0.2  0. ]
 [ 0.   7.9  0.1]
 [ 0.   0.  12. ]]
─────────────────────────────────────────────────
=============================================
   Ejecucion pr3 sobre hepatitis.data dataset!
=============================================

EJERCICIO 2 (SVM  kernel lineal dataset completo train/test):
acc.: 89.68%
kappa: 68.50%
cf = 
[[ 24   8]
 [  8 115]]

precision.: 93.50%
recall: 93.50%
f1 = 93.50%

─────────────────────────────────────────────────
EJERCICIO 3 (SVM gaussian kernel sobre dataset completo train/test):
acc.: 100.00%
kappa: 100.00%
cf = 
[[ 32   0]
 [  0 123]]

precision.: 100.00%
recall: 100.00%
f1 = 100.00%

─────────────────────────────────────────────────
EJERCICIO 4_1 (SVM cross_validation, linear kernel, K=4):
Sintonizacion:
         L   Kappa(%)
      0.03       20.3
      0.12       33.3
      0.50       32.6
      2.00       32.5
      8.00       26.5
     32.00       28.3
    128.00       23.1
    512.00       20.7
   2048.00       20.7
   8192.00       20.7
  32768.00       20.7
V_mejor=0 kappa=33.29%

Test:
acc.: 79.27%
kappa: 28.28%
cf = 
[[ 3.25  4.75]
 [ 3.75 29.25]]
─────────────────────────────────────────────────
EJERCICIO 4_2 (SVM cross_validation, linear kernel, K=10):
Sintonizacion:
         L   Kappa(%)
      0.03       22.2
      0.12       13.1
      0.50       25.6
      2.00       24.1
      8.00       28.1
     32.00       26.7
    128.00       22.8
    512.00       22.8
   2048.00       22.8
   8192.00       22.8
  32768.00       27.5
V_mejor=8 kappa=28.11%

Test:
acc.: 80.50%
kappa: 47.99%
cf = 
[[ 3.1  1.9]
 [ 2.  13. ]]
─────────────────────────────────────────────────
EJERCICIO 4_3 (SVM cross_validation, gaussian kernel, K=4):
Sintonizacion:
    Lambda           Gamma  Kappa (%)      Mejor
0.03       0.0078125        0.0        0.0
0.03         0.03125        0.0        0.0
0.03           0.125        0.0        0.0
0.03             0.5        0.0        0.0
0.03               2        0.0        0.0
0.03               8        0.0        0.0
0.03              32        0.0        0.0
0.03             128        0.0        0.0
0.12       0.0078125        0.0        0.0
0.12         0.03125        0.0        0.0
0.12           0.125        0.0        0.0
0.12             0.5        0.0        0.0
0.12               2        0.0        0.0
0.12               8        0.0        0.0
0.12              32        0.0        0.0
0.12             128        0.0        0.0
0.50       0.0078125        0.0        0.0
0.50         0.03125        4.6        4.6
0.50           0.125        0.0        4.6
0.50             0.5        0.0        4.6
0.50               2        0.0        4.6
0.50               8        0.0        4.6
0.50              32        0.0        4.6
0.50             128        0.0        4.6
2.00       0.0078125       22.7       22.7
2.00         0.03125       45.2       45.2
2.00           0.125       39.1       45.2
2.00             0.5        0.0       45.2
2.00               2        0.0       45.2
2.00               8        0.0       45.2
2.00              32        0.0       45.2
2.00             128        0.0       45.2
8.00       0.0078125       42.4       45.2
8.00         0.03125       50.6       50.6
8.00           0.125       39.1       50.6
8.00             0.5        0.0       50.6
8.00               2        0.0       50.6
8.00               8        0.0       50.6
8.00              32        0.0       50.6
8.00             128        0.0       50.6
32.00       0.0078125       42.3       50.6
32.00         0.03125       50.6       50.6
32.00           0.125       39.1       50.6
32.00             0.5        0.0       50.6
32.00               2        0.0       50.6
32.00               8        0.0       50.6
32.00              32        0.0       50.6
32.00             128        0.0       50.6
128.00       0.0078125       45.1       50.6
128.00         0.03125       50.6       50.6
128.00           0.125       39.1       50.6
128.00             0.5        0.0       50.6
128.00               2        0.0       50.6
128.00               8        0.0       50.6
128.00              32        0.0       50.6
128.00             128        0.0       50.6
512.00       0.0078125       45.1       50.6
512.00         0.03125       50.6       50.6
512.00           0.125       39.1       50.6
512.00             0.5        0.0       50.6
512.00               2        0.0       50.6
512.00               8        0.0       50.6
512.00              32        0.0       50.6
512.00             128        0.0       50.6
2048.00       0.0078125       45.1       50.6
2048.00         0.03125       50.6       50.6
2048.00           0.125       39.1       50.6
2048.00             0.5        0.0       50.6
2048.00               2        0.0       50.6
2048.00               8        0.0       50.6
2048.00              32        0.0       50.6
2048.00             128        0.0       50.6
8192.00       0.0078125       45.1       50.6
8192.00         0.03125       50.6       50.6
8192.00           0.125       39.1       50.6
8192.00             0.5        0.0       50.6
8192.00               2        0.0       50.6
8192.00               8        0.0       50.6
8192.00              32        0.0       50.6
8192.00             128        0.0       50.6
32768.00       0.0078125       45.1       50.6
32768.00         0.03125       50.6       50.6
32768.00           0.125       39.1       50.6
32768.00             0.5        0.0       50.6
32768.00               2        0.0       50.6
32768.00               8        0.0       50.6
32768.00              32        0.0       50.6
32768.00             128        0.0       50.6
L_mejor=8, G_mejor=0.03125, kappa=50.63%

Test:
acc.: 85.37%
kappa: 54.08%
cf = 
[[ 5.25  2.75]
 [ 3.25 29.75]]
─────────────────────────────────────────────────
EJERCICIO 4_4 (SVM cross_validation, gaussian kernel, K=10):
Sintonizacion:
    Lambda           Gamma  Kappa (%)      Mejor
0.03       0.0078125        0.0        0.0
0.03         0.03125        0.0        0.0
0.03           0.125        0.0        0.0
0.03             0.5        0.0        0.0
0.03               2        0.0        0.0
0.03               8        0.0        0.0
0.03              32        0.0        0.0
0.03             128        0.0        0.0
0.12       0.0078125        0.0        0.0
0.12         0.03125        0.0        0.0
0.12           0.125        0.0        0.0
0.12             0.5        0.0        0.0
0.12               2        0.0        0.0
0.12               8        0.0        0.0
0.12              32        0.0        0.0
0.12             128        0.0        0.0
0.50       0.0078125        0.0        0.0
0.50         0.03125       13.3       13.3
0.50           0.125        0.0       13.3
0.50             0.5        0.0       13.3
0.50               2        0.0       13.3
0.50               8        0.0       13.3
0.50              32        0.0       13.3
0.50             128        0.0       13.3
2.00       0.0078125       18.3       18.3
2.00         0.03125       29.0       29.0
2.00           0.125       35.4       35.4
2.00             0.5        0.0       35.4
2.00               2        0.0       35.4
2.00               8        0.0       35.4
2.00              32        0.0       35.4
2.00             128        0.0       35.4
8.00       0.0078125       34.3       35.4
8.00         0.03125       44.8       44.8
8.00           0.125       37.7       44.8
8.00             0.5        0.0       44.8
8.00               2        0.0       44.8
8.00               8        0.0       44.8
8.00              32        0.0       44.8
8.00             128        0.0       44.8
32.00       0.0078125       45.5       45.5
32.00         0.03125       45.2       45.5
32.00           0.125       37.7       45.5
32.00             0.5        0.0       45.5
32.00               2        0.0       45.5
32.00               8        0.0       45.5
32.00              32        0.0       45.5
32.00             128        0.0       45.5
128.00       0.0078125       43.0       45.5
128.00         0.03125       45.2       45.5
128.00           0.125       37.7       45.5
128.00             0.5        0.0       45.5
128.00               2        0.0       45.5
128.00               8        0.0       45.5
128.00              32        0.0       45.5
128.00             128        0.0       45.5
512.00       0.0078125       39.8       45.5
512.00         0.03125       45.2       45.5
512.00           0.125       37.7       45.5
512.00             0.5        0.0       45.5
512.00               2        0.0       45.5
512.00               8        0.0       45.5
512.00              32        0.0       45.5
512.00             128        0.0       45.5
2048.00       0.0078125       39.8       45.5
2048.00         0.03125       45.2       45.5
2048.00           0.125       37.7       45.5
2048.00             0.5        0.0       45.5
2048.00               2        0.0       45.5
2048.00               8        0.0       45.5
2048.00              32        0.0       45.5
2048.00             128        0.0       45.5
8192.00       0.0078125       39.8       45.5
8192.00         0.03125       45.2       45.5
8192.00           0.125       37.7       45.5
8192.00             0.5        0.0       45.5
8192.00               2        0.0       45.5
8192.00               8        0.0       45.5
8192.00              32        0.0       45.5
8192.00             128        0.0       45.5
32768.00       0.0078125       39.8       45.5
32768.00         0.03125       45.2       45.5
32768.00           0.125       37.7       45.5
32768.00             0.5        0.0       45.5
32768.00               2        0.0       45.5
32768.00               8        0.0       45.5
32768.00              32        0.0       45.5
32768.00             128        0.0       45.5
L_mejor=32, G_mejor=0.0078125, kappa=45.48%

Test:
acc.: 80.50%
kappa: 46.84%
cf = 
[[ 2.9  2.1]
 [ 1.8 13.2]]
─────────────────────────────────────────────────
=============================================
   Ejecucion pr3 sobre Coocur dataset!
=============================================

=============================================
   Ejecucion pr3 sobre LBP dataset!
=============================================

